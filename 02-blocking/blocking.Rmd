---
title: "Introduction to Blocking and Classical Record Linkage"
author: "Brenda Betancourt and Rebecca C. Steorts"
date: |
  | July 10, 2019
  |
  |
output:
  beamer_presentation:
    keep_tex: no
    template: beamer.tex
  ioslides_presentation: default
  slidy_presentation: default
institute: |
  | Department of Statistical Science, affiliated faculty in Computer Science, 
  | Biostatistics and Bioinformatics, the information initiative at Duke (iiD) and
  | the Social Science Research Institute (SSRI) 
  | Duke University and U.S. Census Bureau
  | beka@stat.duke.edu
  | Population Dynamics and Health Program Workshop, University of Michigan
natbib: yes
fig_caption: yes
shortinstitute: bb222@stat.duke.edu
classoption: compress
---

# Blocking and Classical Record Linkage

1. Blocking
- Focus will be on deterministic blocking
2. Classical Record Linkage Methods
- Exact Matching
- String Matching
- Fellegi and Sunter (1969); Newcombe (1959).
3. Demos 
- There are demos illustrating each proposed method


# Computational challenge of entity resolution

- Assume $M$ total records in two databases. 
- Naive record linkage requires $M^2$ record comparisons. 
 

<!-- - Given a total of $M$ records in two databases, one must perform $M^2$ record comparisons.  -->

<!-- - We must make all-to-all records comparisons, which is very inefficient.  -->

<!-- - Example: suppose we have two databases with 5,000 total records $\rightarrow$ 25,000,000 comparisons! -->

<!-- - This means that we must make all-to-all record comparisons, which is very inefficient.  -->

<!-- - The number of record pairs grows quadratically with the size of -->
<!-- the dataset -->
<!--     * Two files with 5,000 records $\rightarrow$ 25,000,000 comparisons! -->
    
![Must perform all-to-all record comparisons.](figures/noblocking_plot.pdf){ width=50% }    


# Blocking

- Blocking partitions similar records into bins or blocks.
<!-- - Blocking filters out dissimilar record pairs.  -->
- Record linkage is only performed within the blocks. 


# Blocking

1. Traditional blocking

- A deterministic partition is formed based upon the data. 
- A partition is created by treating certain fields that are thought to be nearly error-free as fixed. 

Example: Partition of date of birth year. 

2. Probabilistic blocking 

- A probability model is used to cluster the data into blocks/partitions. 

Example: Locality Sensitive Hashing.  

Under both blocking approaches, record pairs that do not meet the blocking criteria are automatically classified as non-matches.


# Example: Traditional blocking

All-to-all record comparisons (left) versus partitioning records into
blocks by lastname initial and comparing records only within each partition (right).

![alt text](figures/noblocking_plot.pdf){ width=40% }
![alt text](figures/blocking_plot.pdf){ width=40% }


# Example: RLdata500

```{r, eval=TRUE, message=FALSE, warning=FALSE}
library(RecordLinkage)
data(RLdata500)
head(RLdata500)
```

# Continuation: RLdata500

```{r, eval=TRUE, message=FALSE, warning=FALSE}

# Record pairs for comparison
choose(500,2)

# Blocking by last name initial  
last_init <- substr(RLdata500[,"lname_c1"], 1, 1)
head(last_init)
# Number of blocks
length(unique(last_init))

```
# Continuation: RLdata500

```{r, eval=TRUE, message=FALSE, warning=FALSE}

# Number of records per block
tbl <- table(last_init)
head(tbl)

# Block sizes can vary a lot
summary(as.numeric(tbl))

```

# Continuation: RLdata500

```{r, eval=TRUE, message=FALSE, warning=FALSE}

# Number of records pairs per block
sapply(tbl, choose, k=2)

# Reduction on comparison space
sum(sapply(tbl, choose, k=2))
```

# Continuation: RLdata500

What is the reduction from the overall space to the reduced space? 

Hint: The original space of comparisons was 
```{r, eval=TRUE, message=FALSE, warning=FALSE}
choose(500,2)
```
and  we have reduced the number of comparisons to 
```{r, eval=TRUE, message=FALSE, warning=FALSE}
sum(sapply(tbl, choose, k=2))
```

# Blocking caveats

- Features often contain errors, noise, etc. and may not be suitable for determistic blocking. 


- A noisy feature used for determisitic blocking can miss a large proportion of matches (i.e. increased false negatives rates).



- The frequency distribution of the values of the blocking features will affect the block sizes.


- There is a trade off between the size of the blocks and computational efficency.
    * If the blocks are too big, then the computational speed increases.
     *  If the blocks are too small, then true matches may be missed.




<!-- \vspace{3mm} -->

<!-- - The frequency distribution of the values in the fields used as blocking keys will affect the size of the blocks. -->

<!-- \vspace{3mm} -->

<!-- - Trade-off between block sizes: true matches being missed vs computational efficiency. -->

# How to choose the blocking features (variables or keys)

- Features containing the fewest errors or missing values should be chosen as blocking variables. 

\vspace{3mm}

- Understand the kind of errors that are unlikely for a certain feature. 

\vspace{3mm}

- More complex blocking schemes can be constructed using conjunctions.
    * Retain only pairs which agree on last name initial and zip code.

<!-- # Example: Voter Survey data -->

<!-- The Views of the Electorate Research (VOTER) Survey was conducted by the survey firm YouGov.  -->

<!-- \vspace{2mm} -->

<!-- - 8,000 adults (age 18+) with internet access took the survey on-line between November 29 and December 29, 2016. -->

<!-- \vspace{2mm} -->

<!-- - These respondents were originally interviewed by YouGov in 2011-2012. -->

<!-- \vspace{2mm} -->

<!-- - Barack Obama (Democrat) won in 2012 and Donald Trump (Republican) won in 2016. -->

<!-- \textcolor{blue}{https://www.voterstudygroup.org} -->




<!-- # Continuation: Voter Survey data -->

<!-- - Demographic variables -->
<!--     * Year of birth (age)  -->
<!--     * Gender -->
<!--     * Race -->
<!--     * State -->
<!--     * Education level -->
<!--     * Family income -->

<!-- \vspace{3mm} -->

<!-- - Party affiliation: democrat, republican, independent, other  -->

<!-- \vspace{3mm} -->

<!-- Which fields are reliable for blocking in this example? -->

<!-- # Continuation: Is race reliable? -->

<!-- \definecolor{LightCyan}{rgb}{0.88,1,1} -->
<!-- \definecolor{Gray}{gray}{0.9} -->
<!-- \begin{center} -->
<!-- \begin{tabular}{l|cc} -->

<!--            &     2012 &  2016 \\  -->
<!-- \hline \hline           -->
<!-- White      &     6244 &  6198 \\  -->
<!-- Black      &       654 &  645 \\  -->
<!-- Hispanic   &      400 &  397  \\  -->
<!-- Mixed      &       160 &  186  \\  -->
<!-- Other      &      137 &  167  \\  -->
<!-- Asian      &       117 &  118  \\  -->
<!-- Native American &   60 &   59 \\  -->
<!-- Middle Eastern  &  10 &   12 \\ \hline \hline -->
<!-- \end{tabular} -->

<!-- \begin{tabular}{r|cccc} -->
<!--       & White & Black & Mixed & Other \\  -->
<!-- \hline \hline       -->
<!-- White & 6073  &   5   & {\cellcolor{LightCyan}46}    & 74 \\  -->
<!-- Black &    4  & 627   & 10    & 10 \\  -->
<!-- Mixed &  {\cellcolor{LightCyan}31}  &   6   & 100   &  8 \\  -->
<!-- Other &   50  &   4   & 14    & 62 \\ \hline \hline -->
<!-- \end{tabular} -->
<!-- \end{center} -->

<!-- # Continuation: Is party affiliation reliable? -->

<!-- \begin{center} -->
<!-- \begin{tabular}{l|ccccc} -->
<!--            & Democrat   & Indepen.  & Republican & Not sure & Other\\ -->
<!-- \hline \hline             -->
<!--   Democrat    &    2424   &       192   &      90   &    25  &   23 \\ -->
<!--   Indepen. &     263   &     1929    &    221    &   16  &  57 \\ -->
<!--   Republican  &      39   &      215    &   1881    &   11  &  60 \\ -->
<!--   Not sure    &      48   &       48    &     54    &   41  &   5 \\ -->
<!--   Other       &      17   &       46    &     34    &    2  &  41 \\ -->
<!--   \hline \hline -->
<!-- \end{tabular} -->
<!-- \end{center} -->


#  Classical Record Linkage: Exact matching 

- Exact matching is a method that says two records are a match if they agree on every feature.  

- Performing exact matching is very common in the social and health sciences in practice, however, this is not common in statistics, computer science, or machine learning. 

- Other types of matching or merging are used, where records are called to be a match if they agree based upon a similarity comparison or a probabilitistic model. 

- Examples include: string matching, Fellegi-Sunter method, semi-supervised methods, and hashing techniques. 

<!-- \vspace{1mm} -->

<!-- - Matching that allows fields to only be similar rather than exact duplicates. -->

<!-- \vspace{1mm} -->

<!-- # Example: Iterative deterministic linkage -->

<!-- \textcolor{blue}{Step 1:} two records must match on SSN and one of the following: -->

<!-- \vspace{1mm} -->

<!-- - First and last name. -->
<!-- - Last name, month of birth, and sex. -->
<!-- - First name, month of birth, and sex. -->

<!-- \vspace{1mm} -->

<!-- \textcolor{blue}{Step 2:} If SSN is missing or does not match, two records must match on last name, first name, month of birth, sex, and one of the following: -->

<!-- \vspace{1mm} -->

<!-- - Seven to eight digits of the SSN. -->
<!-- - Two or more of the following: year of birth, day of birth, middle initial, or date of death. -->

<!-- it would end up being an approximate matching that is a result of a two step deterministic matching -->

# Classical Record Linkage: Similarity metrics 

- \textcolor{blue}{Levenshtein (edit) (1966)}: minimum number of substitutions required to transform one string into another e.g. A\textcolor{red}{d}a\textcolor{blue}{m} vs A\textcolor{blue}{l}a\textcolor{blue}{n} has a distance $L=2$, normalized as $1-\frac{L}{maxLength} = 0.5$ for similarity.

\vspace{1mm}

- \textcolor{blue}{Jaro-Winkler (1990):} The Jaro distance (1989) considers common characters and character transpositions. The JW similarity measure is:

\begin{center}
$ JW(A,B)= J(A,B) + \textcolor{red}{0.1p}(1-J(A,B)) $
\end{center}

where $p$ is the \# of the first four characters that agree exactly e.g. Adam vs Alan: p=1,  J= 0.67 and JW=0.7.

These work well on English names that are less than 7 characters. 

<!-- k-grams or k-shingles are better for longer or multi-word strings -->

# Example: RLdata500

```{r, eval=TRUE, message=FALSE, warning=FALSE}
library(RecordLinkage)
data(RLdata500)
```
```{r, eval=TRUE, echo=F, message=FALSE, warning=FALSE}
library(RecordLinkage)
data(RLdata500)
# Code to extract subset of duplicate records
RLdata500c <- RLdata500[,-c(2,4)]
cln <- table(identity.RLdata500)
iddup <- which(cln>1)-1
dup <- which(identity.RLdata500%in%iddup)
sub_dup <- RLdata500c[dup,]
oid <- order(identity.RLdata500[dup])
dup_set <- sub_dup[oid,]
tail(dup_set)
```

# Example: RLdata500

```{r, eval=TRUE, message=FALSE, warning=FALSE}
# Levenshtein similarity 
levenshteinSim("SCHUTE", "SCHULTE")
levenshteinSim("CHRISTA", "CHRISTAH")
# Jaro-Winkler similarity
jarowinkler(c("SCHUTE","CHRISTA"),
            c("SCHULTE","CHRISTAH"))
```

# Similarity metrics (continued) 

- The Soundex algorithm generates a code representing the phonetic pronunciation of a word. 
- This is typicall more useful on non-English names or longer names. 
- The Soundex code for a name consists of a letter followed by three numerical digits: 
    * the letter is the first letter of the name,
    * the digits encode the remaining consonants.
- Consonants at a similar place of articulation share the same digit 
    * The consonants B, F, P and V are each encoded by a 1.

# Example: Soundex algorithm
```{r, eval=TRUE, echo=F, message=FALSE, warning=FALSE}
tail(dup_set)
```
```{r, eval=TRUE, message=FALSE, warning=FALSE}
tail(soundex(dup_set$fname_c1))
tail(soundex(dup_set$lname_c1))
```

# Example: Soundex algorithm

```{r, eval=TRUE, echo=F, message=FALSE, warning=FALSE}
head(dup_set)
```
```{r, eval=TRUE, message=FALSE, warning=FALSE}
head(soundex(dup_set$lname_c1))
```

# Blocking by disjunctions 

- Produces overlapping blocks of the data.
    * \textcolor{blue}{Disjunction}: records match on field A or field B

\vspace{3mm}

- Using multiple keys to consider typographical
or measurement errors that would exclude true matches.
    * Blocking by last name initial or zip code
    
\begin{center}
\begin{tabular}{ l l l l }
 {\color{blue}\emph{1.}} & Mary Clain & 123 Oak St & 90210 \\
 {\color{blue}\emph{2.}} & Mary Klein & 123 Oak Street & 90210 \\
 {\color{blue}\emph{3.}} & Mary Klain & 123 Oak St & 50210 \\
\end{tabular}
\end{center}

- Reduction in false negative rates.

# Example: Blocking by disjunctions

```{r, eval=TRUE, message=FALSE, warning=FALSE}
# Two records must agree in either first name initial 
# or bith year to be compared.
# Only 2709 pairs instead of 124750!

# Builds comparison patterns of record pairs 
rpairs <- compare.dedup(RLdata500c, 
blockfld = list(1, 3), #list with blocking fields
identity = identity.RLdata500)

tail(rpairs$pairs)
```

# Example: String comparison and blocking

```{r, eval=TRUE, message=FALSE, warning=FALSE}
rpairsfuzzy <- compare.dedup(RLdata500c, 
               phonetic = FALSE, blockfld = 3, 
               strcmp = TRUE, strcmpfun = jarowinkler)

tail(rpairsfuzzy$pairs)
```

# Fellegi-Sunter (1969); Newcombe (1959)

- Fellegi-Sunter (1969); Newcombe (1959) proposed the first method for record linkage.
- Records are determined to be a match/non-match using a likelihood ratio test, which can be written as a mixture model. 
- String metrics were used for names/numerical data (Levenshtein or Jaro-Winkler).

# Fellegi-Sunter (1969); Newcombe (1959)

- There are feature vector for record pairs, which are classfied into matches $(M)$, nonmatches $(U)$, and possible matches.

\vspace{2mm}

- Let $P(\gamma|M)$ and $P(\gamma|U)$ be probabilities of observing a feature vector $\gamma$ for a matched and nonmatched pair, respectively.

# Fellegi-Sunter (1969); Newcombe (1959)

- Perform record-pair classification by calculating the ratio $$w=(P(\gamma|M)/P(\gamma|U))$$ for each candidate record pair.

\vspace{2mm}

- Find two thresholds based on desired error levels to optimally separate the weight values for matches, possible matches, and nonmatches.\footnote{This method is very sensitive to the valueds of the thresholds.}

\vspace{2mm}

-  The quality of classification of the Fellegi-Sunter method relies strongly on reasonable estimations of $M$ and $U$ probabilities.

# Example: Blocking and Fellegi-Sunter

```{r, eval=TRUE, message=FALSE, warning=FALSE}

# tail(rpairs$pairs)
# Using comparison data blocking by first name initial
# and birth year
rpairs1 <- epiWeights(rpairs)

# Weights to compute thresholds for classification
rpairs1$Wdata[1:5]
```
# Example: Fellegi-Sunter

```{r, eval=FALSE, message=FALSE, warning=FALSE}
summary(rpairs1)
```

Weight distribution:

\begin{center}
\begin{tabular}{ccccc}
(0.35,0.4] & (0.4,0.45] & (0.45,0.5] & (0.55,0.6] & (0.6,0.65]\\      
      2    &     10     &       30   &      50    &      8 \\
(0.65,0.7] & (0.7,0.75] & (0.75,0.8] & (0.8,0.85] & (0.85,0.9] \\
     0     &     0     &        35  &        8   &       3 \\
\end{tabular}
\end{center}

# Example: Fellegi-Sunter

```{r, eval=FALSE, message=FALSE, warning=FALSE}
result <- epiClassify(rpairs1, 0.7)
summary(result)

alpha error: 0.080000 # False negative rate
beta error: 0.000000  # False positive rate
accuracy: 0.998523

Classification table:

           classification
true status    N    P    L
      FALSE 2659    0    0
      TRUE     4    0   46
```

# Summary

- \textcolor{blue}{Blocking}: reduce comparison space by choosing relatively noise free fields to match records 
    * Use conjunctions (and) create a partition of the data or disjunctions (or) to create overlapping blocks.
    
\vspace{2mm}

- \textcolor{blue}{Strings}: choose a string similarity metric to compare
record pairs within blocks.
    * Levenshtein or Jaro-Winkler.

\vspace{2mm}

- \textcolor{blue}{Record linkage}: use Fellegi-Sunter method to classify records as matches, posibble matches or nonmathches.


# References

\small

- Sariyar M. and Borg A. (2010), The RecordLinkage Package: Detecting
Errors in Data, The R Journal Vol. 2/2. \textcolor{blue}{Check big data functions of the package (>=1'000,000 record pairs).}

- Steorts et al. (2014) A Comparison of Blocking Methods for Record Linkage. In: Domingo-Ferrer J. (eds) Privacy in Statistical Databases. PSD 2014. Lecture Notes in Computer Science, vol 8744. Springer, Cham.

- Fellegi I.P., Sunter A.B. (1969), A Theory for Record Linkage, Journal of the American Statistical Association 64(328), pp. 1183â€“1210.

- Dusetzina et al. Linking Data for Health Services Research: A Framework and Instructional Guide. Rockville (MD): Agency for Healthcare Research and Quality (US) (2014). An Overview of Record Linkage Methods. https://www.ncbi.nlm.nih.gov/books/NBK253312/

- Entity Resolution and Information Quality, John R. Talburt, Elsevier (2011)

<!--
# Cluster-based Blocking

- Records agree on the blocking variables but are still very different 
    * e.g. two different people with the same lastname initial and gender

\vspace{2mm}

- The records in a cluster should be similar and therefore good candidate pairs for linkage.

\vspace{2mm}

- Methods to find clusters based on strings and cheap distance measures  
    * Threshold Nearest Neighbor 
    * K-Nearest Neighbor 
    * Canopies (fuzzy blocking)

# TNN and KNN

- Start with a single record as the base of the first cluster.

\vspace{2mm}

- Recursively add the nearest neighbors of records to the cluster until the distance to the nearest neighbor exceeds some threshold $t$.

\vspace{2mm}

- Choose one of the remaining records to start the next cluster.

\vspace{2mm}

- For KNN, ensure that each cluster has at least k records.

# Canopies

- Canopies is not strictly a blocking method $\rightarrow$ fuzzy blocking

\vspace{1mm}

- Records can be assigned to multiple blocks $\rightarrow$ overlapping clusters not a partition of the data.
    * Randomly pick a record to be the base of the first canopy
    * Records within distance $t_1$ are grouped into that canopy 
    * Remove records within distance $t_2 \leq t_1$ of the base
    * Pick another new record to start a second canopy


# Drawbacks

- Rough distance measures for complicated high-dimensional records are non-trivial.

\vspace{2mm}

- Requires actually performing all or nearly all comparisons to compute  
pairwise distances.

\vspace{2mm}

- Note that performing traditional blocking as a first step can reduce the space considerably.

[[I think I'd like to talk about hierarchical clustering and kmeans and show an illustration with the package, don't know if instead of TNN and KNN or added]]
-->